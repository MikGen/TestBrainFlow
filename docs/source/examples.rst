.. _examples:Examples========Here we provide four examples, the first two examples reproduce some of the results from [#Genkin2020]_, and the last two reproduce some of the results from  [#Genkin2020preprint]_. The first example generates synthetic data from a double-well potential and uses this data to fit the model potential. It reproduces Figure 3 in the main text [#Genkin2020]_. The second example demonstrates our feature consistency model selection method using fitting results from two independent data samples generated from the same ground-truth model. It reproduces Figure 5 in the main text [#Genkin2020]_.The third example generates synthetic data from the ramping dynamics, and optimizes the model potential on this data under four different assumptions. It reproduces Figures 2,3 in the main text [#Genkin2020preprint]_. The fourth example generates two synthetic datasets from ramping and stepping dynamics, and usesthis data to infer the model potentials. It also infers the model potential, the initial distribution of the latent states, and the noise magnitude from data generated from the ramping dynamics.  It reproduces Figures 4 in the main text [#Genkin2020preprint]_.These examples can also be accessed with Jupiter notebook from our `GitHub repository <https://github.com/engellab/neuralflow/>`_ ... toctree::    :maxdepth: 2        examples/Example1.ipynb    examples/Example2.ipynb    examples/Example3.ipynb    examples/Example4.ipynb        References----------.. [#Genkin2020] `Genkin, M., Engel, T.A. Moving beyond generalization to accurate interpretation of flexible models. Nat Mach Intell 2, 674â€“683 (2020). <https://www.nature.com/articles/s42256-020-00242-6>`_.. [#Genkin2020Preprint] `Genkin, M., Hughes, O. and Engel, T.A. Learning non-stationary Langevin dynamics from stochastic observations of latent trajectories. arXiv preprint arXiv:2012.14944 (2020). <https://arxiv.org/abs/2012.14944>`_